_Configurations__run_size:
  end: 1231
  start: 0
_Configurations__run_size_ratio:
  end: 1.0
  start: 0.0
_from_column: true
a2c: true
activation: softmax
activation_last_layer: softmax
bars: 10
batch_size: 32
cnn: false
commission: 0.001
cpu_cores: 10
data: numpy array of size (1231, 85)
data_as_df: false
data_filter: Date>20200200 & Date<=20200414
episodes: 192
epsilon: 0.192
epsilon_decay: 0.99999
epsilon_end: 0.1
epsilon_min: 0.05
epsilon_start: 0.192
epsilon_steps: 92
gpu_cores: 1
ignore_columns: []
investment: 20000
join_columns:
- Date
- Hour
join_columns_data: Dataframe with columns Index(['Date', 'Hour'], dtype='object')
  and size (1248, 2)
load_model: D:/Thesis/bda-deep-rl/experiments/a2c/softmax-cce-adam_ti_128x256/training/models
loss: categorical_crossentropy
loss_critic: null
memory_size: 32
mode: train
model_directory: D:/Thesis/bda-deep-rl/experiments/a2c/softmax-cce-adam_ti_128x256/training2\models
n_stocks: 5
nn_layers:
- 128
- 256
optimizer: adam
output: D:/Thesis/bda-deep-rl/experiments/a2c/softmax-cce-adam_ti_128x256/training2
prices: 'numpy array of size (5,)

  [ 3 20 37 54 71]'
random_memory_sampling: false
reward_directory: D:/Thesis/bda-deep-rl/experiments/a2c/softmax-cce-adam_ti_128x256/training2\rewards
technical_indicators: true
train_directory: D:/Thesis/bda-deep-rl/experiments/a2c/softmax-cce-adam_ti_128x256/../../../data/hourly/
train_file: null
