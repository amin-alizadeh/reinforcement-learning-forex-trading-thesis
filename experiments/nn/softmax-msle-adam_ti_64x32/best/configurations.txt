_Configurations__run_size:
  end: 288
  start: 0
_Configurations__run_size_ratio:
  end: 1.0
  start: 0.0
_from_column: true
a2c: false
activation: softmax
activation_last_layer: null
bars: 10
batch_size: 32
cnn: false
commission: 0.001
cpu_cores: 2
data: numpy array of size (288, 85)
data_as_df: false
data_filter: Date>20200100
episodes: 1
epsilon: 0.0
epsilon_decay: 0.995
epsilon_end: 0.0
epsilon_min: 0.05
epsilon_start: 0.0
epsilon_steps: 100
gpu_cores: 0
ignore_columns: []
investment: 20000
join_columns:
- Date
join_columns_data: Dataframe with columns Index(['Date'], dtype='object') and size
  (305, 1)
load_model: D:/Thesis/bda-deep-rl/softmax-msle-adam/nn-64x32/training/models/best
loss: msle
memory_size: 32
mode: test
model_directory: D:/Thesis/bda-deep-rl/softmax-msle-adam/nn-64x32/best\models
n_stocks: 5
nn_layers:
- 64
- 32
optimizer: adam
output: D:/Thesis/bda-deep-rl/softmax-msle-adam/nn-64x32/best
prices: 'numpy array of size (5,)

  [ 3 20 37 54 71]'
random_memory_sampling: false
reward_directory: D:/Thesis/bda-deep-rl/softmax-msle-adam/nn-64x32/best\rewards
technical_indicators: true
train_directory: D:/Thesis/bda-deep-rl/softmax-msle-adam/nn-64x32/../../data/daily/
train_file: null
